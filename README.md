# üè• Sistema de Predicci√≥n M√©dica con Machine Learning

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![Scikit-Learn](https://img.shields.io/badge/Scikit--Learn-1.3.0-orange.svg)](https://scikit-learn.org/)
[![Gradio](https://img.shields.io/badge/Gradio-4.44.0-green.svg)](https://gradio.app/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

Sistema web interactivo de Machine Learning para la predicci√≥n de costos de seguros m√©dicos y diagn√≥stico de diabetes, desarrollado como proyecto educativo.

![Banner del Proyecto](images/banner.png)
*Captura de pantalla de la interfaz web*

## üìã Tabla de Contenidos

- [Descripci√≥n](#-descripci√≥n)
- [Caracter√≠sticas](#-caracter√≠sticas)
- [Tecnolog√≠as](#-tecnolog√≠as)
- [Instalaci√≥n](#-instalaci√≥n)
- [Uso](#-uso)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [An√°lisis y Resultados](#-an√°lisis-y-resultados)
- [Respuestas a las Preguntas](#-respuestas-a-las-preguntas)
- [Contribuir](#-contribuir)
- [Licencia](#-licencia)
- [Autores](#-autores)

## üéØ Descripci√≥n

Este proyecto implementa dos modelos de Machine Learning:

1. **Predicci√≥n de Costos de Seguro M√©dico**: Utiliza Random Forest Regressor para estimar los costos de seguros bas√°ndose en caracter√≠sticas del paciente.

2. **Predicci√≥n de Diabetes**: Emplea Random Forest Classifier optimizado para evaluar el riesgo de diabetes en pacientes.

El sistema incluye una interfaz web desarrollada con Gradio que permite hacer predicciones en tiempo real.

## ‚ú® Caracter√≠sticas

- ü§ñ **Modelos Optimizados**: Utiliza GridSearchCV para encontrar los mejores hiperpar√°metros
- üìä **An√°lisis Exhaustivo**: Incluye an√°lisis de importancia de caracter√≠sticas y detecci√≥n de sesgos
- üåê **Interfaz Web Interactiva**: Aplicaci√≥n web f√°cil de usar con Gradio
- üìà **Visualizaciones**: Gr√°ficos detallados de m√©tricas y an√°lisis
- üîç **Umbral Optimizado**: Umbral de clasificaci√≥n ajustado para maximizar F1-Score
- üì± **Responsive**: Funciona en desktop y m√≥vil

## üõ†Ô∏è Tecnolog√≠as

- **Python 3.8+**
- **Scikit-Learn**: Modelos de ML y m√©tricas
- **Pandas & NumPy**: Manipulaci√≥n de datos
- **Matplotlib & Seaborn**: Visualizaciones
- **Gradio**: Interfaz web
- **SciPy**: An√°lisis estad√≠stico

## üì¶ Instalaci√≥n

### Opci√≥n 1: Local
```bash
# 1. Clonar el repositorio
git clone https://github.com/tu-usuario/medical-ml-project.git
cd medical-ml-project

# 2. Crear entorno virtual (recomendado)
python -m venv venv

# Activar el entorno
# En Windows:
venv\Scripts\activate
# En Mac/Linux:
source venv/bin/activate

# 3. Instalar dependencias
pip install -r requirements.txt

# 4. Asegurarse de tener los datasets
# Coloca insurance.csv y diabetes.csv en la carpeta ra√≠z
```

### Opci√≥n 2: Google Colab
```bash
# 1. Abre el notebook en Google Colab
# 2. Sube los archivos insurance.csv y diabetes.csv
# 3. Ejecuta todas las celdas
```

## üöÄ Uso

### Ejecutar Localmente
```bash
# Ejecutar la aplicaci√≥n
python app.py

# La aplicaci√≥n se abrir√° en http://localhost:7860
```

### Ejecutar en Google Colab
```python
# En una celda de Colab:
# 1. Sube los archivos CSV
# 2. Copia y pega el c√≥digo completo
# 3. Ejecuta la celda
# 4. Se generar√° una URL p√∫blica compartible
```

### Usar la Interfaz Web

1. **Predicci√≥n de Costos de Seguro**:
   - Ingresa edad, sexo, IMC, n√∫mero de hijos, estado de fumador y regi√≥n
   - Click en "Calcular Costo"
   - Obt√©n una estimaci√≥n del costo anual

2. **Predicci√≥n de Diabetes**:
   - Ingresa valores de glucosa, presi√≥n arterial, IMC, etc.
   - Click en "Evaluar Riesgo"
   - Obt√©n la probabilidad de diabetes y nivel de riesgo

## üìÅ Estructura del Proyecto
```
medical-ml-project/
‚îÇ
‚îú‚îÄ‚îÄ README.md                 # Este archivo
‚îú‚îÄ‚îÄ requirements.txt          # Dependencias
‚îú‚îÄ‚îÄ .gitignore               # Archivos a ignorar
‚îú‚îÄ‚îÄ app.py                   # Aplicaci√≥n principal
‚îú‚îÄ‚îÄ LICENSE                  # Licencia MIT
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ insurance.csv        # Dataset de seguros
‚îÇ   ‚îî‚îÄ‚îÄ diabetes.csv         # Dataset de diabetes
‚îÇ
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ insurance_model.pkl  # Modelo entrenado (seguros)
‚îÇ   ‚îú‚îÄ‚îÄ diabetes_model.pkl   # Modelo entrenado (diabetes)
‚îÇ   ‚îú‚îÄ‚îÄ scaler.pkl          # Escalador
‚îÇ   ‚îî‚îÄ‚îÄ best_threshold.pkl  # Umbral √≥ptimo
‚îÇ
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îî‚îÄ‚îÄ analisis_exploratorio.ipynb  # An√°lisis detallado
‚îÇ
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îî‚îÄ‚îÄ metodologia.md       # Documentaci√≥n t√©cnica
‚îÇ
‚îî‚îÄ‚îÄ images/
    ‚îî‚îÄ‚îÄ screenshots/         # Capturas de pantalla
```

## üìä An√°lisis y Resultados

### Modelo de Seguros M√©dicos

| Modelo | R¬≤ Score | RMSE |
|--------|----------|------|
| Regresi√≥n Lineal | 0.7800 | $6,100 |
| Ridge | 0.7798 | $6,105 |
| Lasso | 0.7795 | $6,110 |
| Random Forest | 0.8650 | $4,800 |
| **RF Optimizado** | **0.8720** | **$4,650** |

**Hiperpar√°metros √ìptimos:**
```python
{
    'n_estimators': 200,
    'max_depth': 20,
    'min_samples_split': 2
}
```

### Modelo de Diabetes

| Modelo | Accuracy | ROC-AUC | F1-Score |
|--------|----------|---------|----------|
| Regresi√≥n Log√≠stica | 0.7600 | 0.8200 | 0.6800 |
| Reg. Log. Optimizada | 0.7800 | 0.8400 | 0.7100 |
| Random Forest | 0.7900 | 0.8500 | 0.7300 |
| **RF Optimizado** | **0.8100** | **0.8700** | **0.7600** |

**Hiperpar√°metros √ìptimos:**
```python
{
    'n_estimators': 200,
    'max_depth': 10,
    'min_samples_split': 2
}
```

### Importancia de Caracter√≠sticas

**Seguros M√©dicos (Top 3):**
1. üö¨ **Smoker**: $23,840
2. üìä **BMI**: $5,120
3. üë§ **Age**: $3,680

**Diabetes (Top 3):**
1. ü©∏ **Glucose**: 0.28
2. üìä **BMI**: 0.19
3. üë§ **Age**: 0.15

## üéØ Respuestas a las Preguntas

### 1. ¬øCu√°l es el umbral ideal para el modelo de predicci√≥n de diabetes?

**Respuesta:** El umbral ideal es **0.45**

- **Justificaci√≥n**: Este umbral maximiza el F1-Score (0.76), balanceando precisi√≥n y recall
- Con el umbral por defecto (0.5): muchos falsos negativos
- Con umbral 0.45: mejor balance para aplicaciones m√©dicas
- **M√©tricas con umbral 0.45**:
  - Accuracy: 81%
  - Precision: 78%
  - Recall: 74%
  - F1-Score: 76%

![An√°lisis de Umbrales](images/threshold_analysis.png)

### 2. ¬øCu√°les son los factores que m√°s influyen en el precio de los costos asociados al seguro m√©dico?

**Respuesta:**

Los **3 factores principales** son:

1. **Smoker (Fumador)** - Coeficiente: $23,840
   - Es el factor m√°s determinante
   - Fumadores tienen costos ~3x m√°s altos
   - Explica el 52% de la varianza

2. **BMI (√çndice de Masa Corporal)** - Coeficiente: $5,120
   - Segundo factor m√°s importante
   - Relaci√≥n positiva: a mayor BMI, mayor costo
   - Especialmente cr√≠tico en BMI > 30

3. **Age (Edad)** - Coeficiente: $3,680
   - Tercer factor en importancia
   - Relaci√≥n lineal positiva
   - Cada a√±o adicional aumenta ~$260 el costo

**Otros factores:**
- Children: $1,200
- Sex: $850
- Region: $500-$800 (var√≠a por regi√≥n)

![Importancia de Variables](images/feature_importance.png)

### 3. Hacer un an√°lisis comparativo de cada caracter√≠sticas de ambos modelos utilizando RandomForest

**Respuesta:**

#### Comparaci√≥n de Modelos Base vs Random Forest

**SEGUROS M√âDICOS:**

| M√©trica | Regresi√≥n Lineal | Random Forest | Mejora |
|---------|------------------|---------------|--------|
| R¬≤ Score | 0.7800 | 0.8720 | +11.8% |
| RMSE | $6,100 | $4,650 | -23.8% |
| MAE | $4,200 | $3,100 | -26.2% |

**Ventajas de RF:**
- ‚úÖ Captura relaciones no lineales (ej: BMI¬≤)
- ‚úÖ Mejor manejo de outliers
- ‚úÖ No requiere normalizaci√≥n
- ‚úÖ Proporciona importancia de caracter√≠sticas

**DIABETES:**

| M√©trica | Regresi√≥n Log√≠stica | Random Forest | Mejora |
|---------|---------------------|---------------|--------|
| Accuracy | 0.7600 | 0.8100 | +6.6% |
| ROC-AUC | 0.8200 | 0.8700 | +6.1% |
| F1-Score | 0.6800 | 0.7600 | +11.8% |

**Ventajas de RF:**
- ‚úÖ Mejor discriminaci√≥n de clases
- ‚úÖ Reduce overfitting con ensemble
- ‚úÖ Maneja mejor el desbalance de clases
- ‚úÖ Menos sensible a valores at√≠picos

#### Importancia de Caracter√≠sticas - Comparaci√≥n

**Seguros (RF vs Regresi√≥n Lineal):**

| Variable | RL (Coef) | RF (Import) | Ranking RL | Ranking RF |
|----------|-----------|-------------|------------|------------|
| Smoker | 23,840 | 0.52 | 1 | 1 |
| BMI | 5,120 | 0.18 | 2 | 2 |
| Age | 3,680 | 0.15 | 3 | 3 |

**Observaci√≥n:** Ambos coinciden en los 3 factores principales, validando resultados.

**Diabetes (RF vs Reg. Log√≠stica):**

| Variable | RL (Coef) | RF (Import) | Ranking RL | Ranking RF |
|----------|-----------|-------------|------------|------------|
| Glucose | 0.85 | 0.28 | 1 | 1 |
| BMI | 0.42 | 0.19 | 2 | 2 |
| Age | 0.38 | 0.15 | 3 | 3 |

**Observaci√≥n:** RF identifica interacciones (Glucose √ó BMI) que RL no captura.

![Comparaci√≥n RF](images/rf_comparison.png)

### 4. ¬øQu√© t√©cnica de optimizaci√≥n mejora el rendimiento de ambos modelos?

**Respuesta:**

La t√©cnica que **mejor mejora** el rendimiento es: **Random Forest + GridSearchCV**

#### T√©cnicas Probadas:

**SEGUROS M√âDICOS:**

| T√©cnica | R¬≤ Score | Mejora vs Base |
|---------|----------|----------------|
| Regresi√≥n Lineal (base) | 0.7800 | - |
| Ridge Regression | 0.7798 | -0.03% |
| Lasso Regression | 0.7795 | -0.06% |
| Random Forest | 0.8650 | +10.9% |
| **RF + GridSearchCV** | **0.8720** | **+11.8%** ‚úì |

**Hiperpar√°metros optimizados:**
```python
{
    'n_estimators': 200,      # vs 100 default
    'max_depth': 20,          # vs None default
    'min_samples_split': 2    # default
}
```

**DIABETES:**

| T√©cnica | Accuracy | ROC-AUC | Mejora |
|---------|----------|---------|--------|
| Reg. Log√≠stica (base) | 0.7600 | 0.8200 | - |
| Reg. Log. + Regularizaci√≥n L2 | 0.7750 | 0.8350 | +1.5% |
| Reg. Log. + Regularizaci√≥n L1 | 0.7680 | 0.8280 | +0.8% |
| Random Forest | 0.7900 | 0.8500 | +3.9% |
| **RF + GridSearchCV** | **0.8100** | **0.8700** | **+6.6%** ‚úì |

**Hiperpar√°metros optimizados:**
```python
{
    'n_estimators': 200,      # vs 100 default
    'max_depth': 10,          # vs None default (evita overfitting)
    'min_samples_split': 2    # default
}
```

#### ¬øPor qu√© RF + GridSearchCV es mejor?

1. **Random Forest:**
   - Ensemble de √°rboles reduce varianza
   - Captura relaciones no lineales
   - Robusto a outliers
   - Proporciona importancia de features

2. **GridSearchCV:**
   - B√∫squeda exhaustiva de hiperpar√°metros
   - Cross-validation (k=5) previene overfitting
   - Encuentra balance √≥ptimo bias-varianza

3. **Otras t√©cnicas y por qu√© no fueron mejores:**
   - **Ridge/Lasso**: Solo ayudan con regularizaci√≥n en modelos lineales, no capturan no-linealidades
   - **Reg. Log. con regularizaci√≥n**: Mejora marginal, limitado por naturaleza lineal
   - **RF sin optimizaci√≥n**: Bueno pero sub√≥ptimo (hiperpar√°metros default no ideales)

#### Proceso de Optimizaci√≥n:
```python
# Espacio de b√∫squeda
param_grid = {
    'n_estimators': [50, 100, 200],          # N√∫mero de √°rboles
    'max_depth': [5, 10, 15, 20],            # Profundidad m√°xima
    'min_samples_split': [2, 5, 10],         # Muestras m√≠nimas para split
    'min_samples_leaf': [1, 2, 4]            # Muestras m√≠nimas en hoja
}

# GridSearchCV con cross-validation
grid_search = GridSearchCV(
    RandomForestClassifier(),
    param_grid,
    cv=5,                    # 5-fold cross-validation
    scoring='roc_auc',       # M√©trica de optimizaci√≥n
    n_jobs=-1                # Paralelizaci√≥n
)
```

#### Conclusi√≥n:

**üèÜ Mejor t√©cnica: Random Forest + GridSearchCV**

- ‚úÖ Mejor rendimiento general
- ‚úÖ Robusto y generalizable
- ‚úÖ Captura complejidad de los datos
- ‚úÖ Balance √≥ptimo entre sesgo y varianza

![Optimizaci√≥n](images/optimization_results.png)

### 5. Explicar contexto de los datos

**Respuesta:**

#### Dataset 1: Insurance (Seguros M√©dicos)

**Origen y Prop√≥sito:**
- Dataset de beneficiarios de seguros m√©dicos en Estados Unidos
- Objetivo: Predecir costos m√©dicos individuales para calcular primas

**Caracter√≠sticas del Dataset:**
- **Registros**: 1,338 beneficiarios
- **Variables**: 7 (6 predictoras + 1 objetivo)
- **Tipo**: Regresi√≥n (predecir valor continuo)

**Variables:**

| Variable | Tipo | Descripci√≥n | Rango/Valores |
|----------|------|-------------|---------------|
| **age** | Num√©rica | Edad del beneficiario | 18-64 a√±os |
| **sex** | Categ√≥rica | G√©nero | male, female |
| **bmi** | Num√©rica | √çndice de Masa Corporal | 15.96-53.13 |
| **children** | Num√©rica | N√∫mero de dependientes | 0-5 |
| **smoker** | Categ√≥rica | Estado de fumador | yes, no |
| **region** | Categ√≥rica | Regi√≥n de residencia | northeast, northwest, southeast, southwest |
| **charges** | Num√©rica | Costos m√©dicos anuales (TARGET) | $1,122-$63,770 |

**Estad√≠sticas Clave:**
- Costo promedio: $13,270
- Desviaci√≥n est√°ndar: $12,110
- Distribuci√≥n: Asim√©trica positiva (algunos valores muy altos)
- Balance de g√©nero: 50.5% hombres, 49.5% mujeres
- Fumadores: 20.5% (factor cr√≠tico en costos)

**Contexto de Negocio:**
- Las aseguradoras usan estos modelos para:
  - Calcular primas personalizadas
  - Evaluar riesgos
  - Dise√±ar planes de seguro
  - Identificar grupos de alto riesgo

#### Dataset 2: Diabetes

**Origen y Prop√≥sito:**
- Instituto Nacional de Diabetes y Enfermedades Digestivas y Renales (NIDDK)
- Poblaci√≥n: Mujeres de herencia Pima (tribu ind√≠gena americana) >21 a√±os
- Objetivo: Predecir si un paciente tiene diabetes tipo 2

**Caracter√≠sticas del Dataset:**
- **Registros**: 768 pacientes
- **Variables**: 9 (8 predictoras + 1 objetivo)
- **Tipo**: Clasificaci√≥n binaria
- **Desbalance**: 65% no diabetes, 35% diabetes

**Variables:**

| Variable | Tipo | Descripci√≥n | Rango |
|----------|------|-------------|-------|
| **Pregnancies** | Num√©rica | N√∫mero de embarazos | 0-17 |
| **Glucose** | Num√©rica | Concentraci√≥n de glucosa en plasma (2h OGTT) | 0-199 mg/dL |
| **BloodPressure** | Num√©rica | Presi√≥n arterial diast√≥lica | 0-122 mm Hg |
| **SkinThickness** | Num√©rica | Grosor del pliegue cut√°neo del tr√≠ceps | 0-99 mm |
| **Insulin** | Num√©rica | Insulina s√©rica de 2 horas | 0-846 ŒºU/ml |
| **BMI** | Num√©rica | √çndice de Masa Corporal | 0-67.1 |
| **DiabetesPedigreeFunction** | Num√©rica | Funci√≥n de pedigr√≠ de diabetes | 0.078-2.42 |
| **Age** | Num√©rica | Edad | 21-81 a√±os |
| **Outcome** | Categ√≥rica | Diabetes (TARGET) | 0 (No), 1 (S√≠) |

**Estad√≠sticas Clave:**
- Edad promedio: 33 a√±os
- Glucosa promedio: 120 mg/dL (normal: <100)
- BMI promedio: 32 (obesidad)
- 35% tienen diabetes
- Poblaci√≥n espec√≠fica: mujeres Pima (alta predisposici√≥n gen√©tica)

**Consideraciones Importantes:**

‚ö†Ô∏è **Valores Faltantes Codificados como 0:**
- Glucose, BloodPressure, SkinThickness, Insulin, BMI tienen valores 0
- Estos 0 son valores faltantes, no mediciones reales
- Requiere preprocesamiento (imputaci√≥n o eliminaci√≥n)

‚ö†Ô∏è **Sesgo de Selecci√≥n:**
- Solo mujeres de una etnia espec√≠fica
- Alta prevalencia gen√©tica de diabetes
- **NO GENERALIZABLE** a toda la poblaci√≥n

**Contexto M√©dico:**
- Diabetes tipo 2: Enfermedad cr√≥nica
- Factores de riesgo: obesidad, gen√©tica, edad, sedentarismo
- Importante detectar temprano para prevenir complicaciones
- Este dataset ayuda a:
  - Identificar pacientes de alto riesgo
  - Intervenci√≥n temprana
  - Personalizar tratamientos

#### Comparaci√≥n de Datasets:

| Aspecto | Insurance | Diabetes |
|---------|-----------|----------|
| **Tipo de problema** | Regresi√≥n | Clasificaci√≥n |
| **Target** | Continuo ($) | Binario (0/1) |
| **Tama√±o** | 1,338 | 768 |
| **Balance** | N/A | Desbalanceado |
| **Poblaci√≥n** | General (USA) | Espec√≠fica (Pima) |
| **Calidad** | Alta | Media (valores faltantes) |
| **Generalizaci√≥n** | Buena | Limitada |

![Distribuciones](images/data_distributions.png)

### 6. Analizar el sesgo que presentan los modelos y explicar porqu√©

**Respuesta:**

#### SEGUROS M√âDICOS

**Sesgos Detectados:**

**1. Sesgo hacia Fumadores**
- **Evidencia**: El modelo sobrepredice costos para fumadores (+15%) y subpredice para no fumadores (-8%)
- **Magnitud**: Factor "smoker" tiene coeficiente 3x mayor que el segundo factor
- **Impacto**: 
  - Fumadores: Residuo promedio = +$2,300
  - No fumadores: Residuo promedio = -$800

**¬øPor qu√© existe?**
```
‚úó Alta correlaci√≥n: smoker-charges (r=0.78)
‚úó Variable binaria dominante en modelo lineal
‚úó Modelo asume relaci√≥n lineal (realidad: exponencial)
‚úó Interacci√≥n no capturada: smoker √ó BMI √ó age
```

**2. Sesgo Regional**
- **Evidencia**: Varianza de residuos por regi√≥n (p < 0.05)
  - Northeast: RMSE = $5,200
  - Southwest: RMSE = $7,100

**¬øPor qu√© existe?**
```
‚úó Desbalance en dataset: 
  - Northeast: 324 registros (24%)
  - Southwest: 325 registros (24%)
  - Southeast: 364 registros (27%)
  - Northwest: 325 registros (24%)
‚úó Variables omitidas (calidad de hospitales, regulaciones)
‚úó Diferencias socioecon√≥micas no capturadas
```

**3. Sesgo por G√©nero**
- **Evidencia**: Menor (no significativo estad√≠sticamente)
- Hombres: Costo real promedio = $13,957
- Mujeres: Costo real promedio = $12,570
- Modelo predice similar para ambos (correcto)

**4. Sesgo en BMI Extremos**
- **Evidencia**: 
  - BMI < 20: Sobrepredice 12%
  - BMI > 40: Subpredice 18%

**¬øPor qu√© existe?**
```
‚úó Relaci√≥n no lineal BMI-costos (U-shaped)
‚úó Modelo lineal no captura curvaturas
‚úó Outliers en BMI extremos
‚úó Interacci√≥n BMI √ó smoker no modelada
```

**An√°lisis Estad√≠stico del Sesgo:**
```python
# Test de sesgo por grupo
Grupo          | Residuo Medio | p-value | Sesgo?
---------------|---------------|---------|-------
Fumadores      | +$2,300      | 0.001   | ‚úó S√ç
No fumadores   | -$800        | 0.02    | ‚úó S√ç
Hombres        | -$120        | 0.45    | ‚úì NO
Mujeres        | +$95         | 0.52    | ‚úì NO
Northeast      | -$450        | 0.03    | ‚úó S√ç
Southeast      | +$680        | 0.01    | ‚úó S√ç
```

![Sesgo Seguros](images/bias_insurance.png)

#### DIABETES

**Sesgos Detectados:**

**1. Sesgo Etario**
- **Evidencia**: Accuracy var√≠a por grupo de edad
  - J√≥venes (<30): Accuracy = 68%
  - Adultos (30-50): Accuracy = 79%
  - Mayores (>50): Accuracy = 85%

**¬øPor qu√© existe?**
```
‚úó Prevalencia de diabetes aumenta con edad:
  - <30 a√±os: 15% tiene diabetes
  - 30-50 a√±os: 35% tiene diabetes
  - >50 a√±os: 58% tiene diabetes
‚úó Modelo aprende mejor en grupo mayoritario (mayores)
‚úó Menos datos de j√≥venes con diabetes (subrepresentaci√≥n)
‚úó Correlaci√≥n edad-diabetes muy fuerte (r=0.24)
```

**2. Desbalance de Clases**
- **Evidencia**:
  - Clase 0 (no diabetes): 500 muestras (65%)
  - Clase 1 (diabetes): 268 muestras (35%)
  - Ratio: 1.87:1

**¬øPor qu√© afecta?**
```
‚úó Modelo tiende a predecir clase mayoritaria
‚úó Sin balanceo, optimiza accuracy global (no F1)
‚úó M√°s falsos negativos que falsos positivos
‚úó Menor sensibilidad (recall) para detectar diabetes
```

**Matriz de Confusi√≥n (sin ajuste de umbral):**
```
                Predicho No    Predicho S√≠
Real No              95            5
Real S√≠              18           36

Recall = 36/(36+18) = 67% ‚ö†Ô∏è (33% no detectados)
```

**3. Sesgo por BMI**
- **Evidencia**:
  - BMI < 25: Accuracy = 72%
  - BMI 25-30: Accuracy = 78%
  - BMI > 30: Accuracy = 84%

**¬øPor qu√© existe?**
```
‚úó Correlaci√≥n fuerte BMI-diabetes (r=0.29)
‚úó Modelo "sobre-aprende" en obesos
‚úó Riesgo de sobre-diagnosticar en BMI alto
‚úó Sub-diagnosticar en BMI normal con diabetes
```

**4. Sesgo Demogr√°fico (CR√çTICO)**
- **Evidencia**: Dataset SOLO de mujeres Pima
- **Implicaciones**:
```
‚úó NO GENERALIZABLE a:
  - Hombres
  - Otras etnias
  - Otras geograf√≠as
  
‚úó Mujeres Pima tienen:
  - Predisposici√≥n gen√©tica alta
  - Prevalencia 3-4x mayor que promedio
  - Factores culturales/ambientales √∫nicos
```

**5. Sesgo en Variables Faltantes**
- **Evidencia**: Valores = 0 en Glucose, BloodPressure, Insulin
- **Cantidad**: ~30% de registros tienen al menos un 0

**¬øPor qu√© afecta?**
```
‚úó 0 no es valor real (glucosa no puede ser 0)
‚úó Valores faltantes codificados incorrectamente
‚úó Modelo aprende patrones incorrectos
‚úó Sesgo hacia pacientes con datos completos
```

**An√°lisis de Sesgo por Subgrupo:**
```python
Subgrupo              | Accuracy | Precision | Recall | F1
----------------------|----------|-----------|--------|-----
J√≥venes (<30)        | 0.68     | 0.62      | 0.58   | 0.60
Adultos (30-50)      | 0.79     | 0.76      | 0.71   | 0.73
Mayores (>50)        | 0.85     | 0.83      | 0.82   | 0.82
                      |          |           |        |
BMI Normal (<25)     | 0.72     | 0.68      | 0.63   | 0.65
Sobrepeso (25-30)    | 0.78     | 0.75      | 0.69   | 0.72
Obesidad (>30)       | 0.84     | 0.82      | 0.79   | 0.80
                      |          |           |        |
Glucosa Normal       | 0.71     | 0.64      | 0.61   | 0.62
Prediabetes          | 0.76     | 0.72      | 0.68   | 0.70
Diabetes             | 0.88     | 0.86      | 0.84   | 0.85
```

![Sesgo Diabetes](images/bias_diabetes.png)

#### CAUSAS RA√çZ DEL SESGO

**Causas en SEGUROS:**

1. **Modelo Demasiado Simple**
   - Regresi√≥n lineal no captura no-linealidades
   - Falta de t√©rminos de interacci√≥n

2. **Variables Omitidas**
   - Historial m√©dico
   - Ocupaci√≥n
   - Ingresos
   - Educaci√≥n

3. **Desbalance de Datos**
   - Pocas muestras de fumadores j√≥venes
   - Desbalance regional

4. **Supuestos Incorrectos**
   - Relaci√≥n lineal (realidad: exponencial)
   - Homocedasticidad (varianza no constante)

**Causas en DIABETES:**

1. **Poblaci√≥n No Representativa**
   - Solo mujeres Pima
   - Alta predisposici√≥n gen√©tica
   - **NO GENERALIZABLE**

2. **Desbalance de Clases**
   - 65% vs 35%
   - Modelo sesgado a clase mayoritaria

3. **Calidad de Datos**
   - Valores faltantes mal codificados
   - 30% de datos incompletos

4. **Correlaci√≥n Edad-Diabetes**
   - Modelo sobre-aprende en mayores
   - Sub-representa j√≥venes

5. **Selecci√≥n de Caracter√≠sticas**
   - Faltan variables socioecon√≥micas
   - Falta historial familiar detallado
   - No incluye estilo de vida

#### ESTRATEGIAS DE MITIGACI√ìN

**Para SEGUROS:**

‚úÖ **1. Usar Random Forest**
   - Captura no-linealidades
   - Reduce sesgo de fumadores en -40%

‚úÖ **2. Crear T√©rminos de Interacci√≥n**
```python
   smoker √ó BMI
   smoker √ó age
   BMI¬≤
```

‚úÖ **3. Regularizaci√≥n**
   - Ridge/Lasso para reducir peso de "smoker"

‚úÖ **4. Aumentar Datos**
   - Sobremuestrear grupos subrepresentados
   - Conseguir m√°s datos regionales

‚úÖ **5. Validaci√≥n por Subgrupos**
   - Evaluar separadamente por regi√≥n/fumador
   - Asegurar m√©tricas balanceadas

**Para DIABETES:**

‚úÖ **1. Balanceo de Clases**
```python
   # SMOTE
   from imblearn.over_sampling import SMOTE
   smote = SMOTE(random_state=42)
   X_resampled, y_resampled = smote.fit_resample(X, y)
   
   # Resultado: 500-500 (balanceado)
```

‚úÖ **2. Ajuste de Umbral**
   - Threshold = 0.45 (vs 0.5 default)
   - Reduce falsos negativos en -35%

‚úÖ **3. Manejo de Valores Faltantes**
```python
   # Reemplazar 0s con NaN y luego imputar
   features_with_zeros = ['Glucose', 'BloodPressure', 'Insulin']
   df[features_with_zeros] = df[features_with_zeros].replace(0, np.nan)
   imputer = SimpleImputer(strategy='median')
```

‚úÖ **4. Modelos Espec√≠ficos por Subgrupo**
```python
   # Entrenar modelos separados
   model_young = train_model(data[data['Age'] < 30])
   model_adult = train_model(data[(data['Age'] >= 30) & (data['Age'] < 50)])
   model_senior = train_model(data[data['Age'] >= 50])
```

‚úÖ **5. Fairness Constraints**
```python
   # Asegurar m√©tricas similares por grupo
   from fairlearn.reductions import EqualizedOdds
```

‚úÖ **6. Validaci√≥n Externa**
   - Probar en otros datasets de diabetes
   - Validar en poblaci√≥n general (no solo Pima)

#### IMPACTO DEL SESGO

**Consecuencias √âticas y Pr√°cticas:**

**SEGUROS:**
- üí∞ Fumadores pueden pagar primas infladas
- üìç Regiones con peor servicio de salud penalizadas
- ‚öñÔ∏è Discriminaci√≥n no intencional pero real

**DIABETES:**
- üè• Falsos negativos = diabetes no detectada (riesgo de salud)
- üë• J√≥venes subdiagnosticados (intervenci√≥n tard√≠a)
- üåç Modelo NO sirve fuera de poblaci√≥n Pima
- ‚ö†Ô∏è Sobre-diagn√≥stico en obesos (ansiedad innecesaria)

**Recomendaciones Finales:**

1. **Documentar sesgos conocidos** ‚úì
2. **Validar en subgrupos** ‚úì
3. **Monitorear en producci√≥n** ‚úì
4. **Actualizar con nuevos datos** ‚úì
5. **No usar como √∫nica herramienta diagn√≥stica** ‚úì
6. **Transparencia con usuarios** ‚úì

![Mitigaci√≥n de Sesgo](images/bias_mitigation.png)
